# Copy this file to .env and fill in your values.
#
# Provider auto-detection priority: Groq → Azure OpenAI → OpenAI
# Set only the keys for the provider you want to use.
# Override with LLM_PROVIDER=groq|azure|openai to force a specific one.

# ── Option A: Groq (fastest, free tier available) ─────────────────────────────
# Get your key at: https://console.groq.com/keys
GROQ_API_KEY=gsk_...
# GROQ_MODEL=llama-3.3-70b-versatile   # default; also try: mixtral-8x7b-32768

# ── Option B: Azure OpenAI ────────────────────────────────────────────────────
# AZURE_OPENAI_API_KEY=your-azure-key-here
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
# AZURE_OPENAI_API_VERSION=2024-12-01-preview
# AZURE_OPENAI_DEPLOYMENT=gpt-4o

# ── Option C: Standard OpenAI ─────────────────────────────────────────────────
# OPENAI_API_KEY=sk-...
# OPENAI_MODEL=gpt-4o-mini

# ── Production: PostgreSQL checkpointing ──────────────────────────────────────
# Swap MemorySaver for PostgresSaver in agent.py build_graph() if using this.
# DATABASE_URL=postgresql://user:password@localhost:5432/agent_db
